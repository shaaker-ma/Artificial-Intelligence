{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f833025",
   "metadata": {
    "id": "8f833025"
   },
   "source": [
    "# <font color='black'><center><center></font> \n",
    "![title](img/All.png) \n",
    "# <font color='white'><center><center></font> \n",
    "# <font><center>Artificial Intelligence<center></font>\n",
    "## <font ><center>CA4: MACHINE LEARNING<center></font>\n",
    "## <center>Teacher: Dr. Fadaei<center>\n",
    "### <center>Student Name: Mohammadali Shakerdargah<center>\n",
    "### <center>Student Number: 810098002<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dddfa7a",
   "metadata": {
    "id": "2dddfa7a"
   },
   "source": [
    "### <font>Purpose:</font>\n",
    "    In this project we are going to use \"scikit-library\" to perform machine learning algorithms on given data so that we can fit a model to estimate each vehicle's price.\n",
    "    \n",
    "### <font>What  we did in this Project:</font>\n",
    "    In this project we are going to had a training dataset and a test data set to evaluate our model we used \"Naive Bayes\" to build a classifier model to predict the category of a book using a description and name of the book\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vxQKaqZxrsfn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vxQKaqZxrsfn",
    "outputId": "2c71ea3f-cde1-45c9-a1fd-2c3c0a492302"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3IsRYXhIqm44",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3IsRYXhIqm44",
    "outputId": "5f5843b3-7c57-4ddc-a957-858fa66ade90"
   },
   "outputs": [],
   "source": [
    "!pip install hazm\n",
    "!pip install https://github.com/sobhe/hazm/archive/master.zip --upgrade\n",
    "!pip install arabic-reshaper\n",
    "!pip install python-bidi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78c5cff",
   "metadata": {
    "id": "f78c5cff"
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "from hazm import *\n",
    "import pandas as pd\n",
    "from numpy import *\n",
    "import math\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "import arabic_reshaper\n",
    "from bidi.algorithm import get_display\n",
    "import sklearn\n",
    "from sklearn import feature_selection\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NAcdoY5brCDE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NAcdoY5brCDE",
    "outputId": "f173d15e-bf1b-41d1-b488-7b058d2f4531"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb6230e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "7eb6230e",
    "outputId": "5e59c299-9468-443e-bce9-b618c46bac56"
   },
   "outputs": [],
   "source": [
    "# data = pd.read_csv(\"/content/drive/MyDrive/Colab_Documents/AI/CA4/vehicles.csv\")\n",
    "data = pd.read_csv(\"vehicles.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a06735",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f7a06735",
    "outputId": "89c1dabd-fbd9-4dec-f0ec-c1d5ffc1b5b3"
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c4d3a1",
   "metadata": {
    "id": "06c4d3a1"
   },
   "source": [
    "# Phase 1: Preprocessing and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681aa39c",
   "metadata": {
    "id": "681aa39c"
   },
   "source": [
    "- First I got rid of those NAN rows. \n",
    "- Then, I changed brands from categorical to numerical values (We only had 26 specific brands). \n",
    "- After erasing NAN rows and changing brands from categorical to numerical, I decided to cleanse my data. In order to cleanse data I used \"hazm\" library.\n",
    "    - it is formal that it is better to work with root of each word. It tells us that prefixes and postfixes are not that necessary for us to participate them in our process.And sometimes they may even reduce our accuracy because all versions of a word are telling us the same thing and almost same info,So we will use 2 methods called \"Stemming\" and \"lemmatization\". these two methods share the same goal, and the goal is to remove unnecessary prefixes and postfixes from a word. I prefered to use \"lemmatization\" because found it beter to use so we won't have (آسمان -> آسم) . It works\n",
    "        - lemmatizer.lemmatize('می‌روم') -> 'رفت#رو'\n",
    "    - I could have gone with \"Stemming\" too and it works like this: \n",
    "        - like this: stemmer.stem('کتاب‌ها') -> 'کتاب'\n",
    "- Then, I tried to change category of the cars into numerical which containes only light cars -> 0\n",
    "- I scaled \"Mileage\" with MinMaxScaler so that we wouldn't have our data in a  big range.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02599acf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "02599acf",
    "outputId": "4056a55b-7eff-47a9-d6f0-8c57ffcd8d59"
   },
   "outputs": [],
   "source": [
    "data = data[pd.notnull(data['brand'])]\n",
    "data = data.reset_index(drop=True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b58cdd",
   "metadata": {
    "id": "c5b58cdd"
   },
   "outputs": [],
   "source": [
    "def brandCategorizer(data, brand, categories):\n",
    "    for i in range(len(data[brand])):\n",
    "        brand_i = data[brand][i]\n",
    "        if(brand_i in categories):\n",
    "            data[brand][i] = categories.get(brand_i)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728a1970",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 895
    },
    "id": "728a1970",
    "outputId": "8bc4eecf-03db-4807-8c2c-c3b0737d44c8"
   },
   "outputs": [],
   "source": [
    "uniqueCategories = data['brand'].unique()\n",
    "categories ={}\n",
    "for i in range(len(uniqueCategories)):\n",
    "    categories[uniqueCategories[i]] = i\n",
    "for category in categories:\n",
    "    print(\"Mapped: \",category,\" -> \", categories.get(category))\n",
    "data = brandCategorizer(data, 'brand', categories)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dd1ee5",
   "metadata": {
    "id": "d8dd1ee5"
   },
   "outputs": [],
   "source": [
    "def dataCleanse(df,col):\n",
    "    normalizer = Normalizer()\n",
    "    lemmatizer = Lemmatizer() \n",
    "    for i in range(len(df[col])):\n",
    "        df[col][i] = normalizer.normalize(df[col][i])\n",
    "            \n",
    "    punctuations = set('''!()-[]{};:'\"\\,٬٫،<>./?@#$%٪^&*×ـ+=_~.؟؛«»|…''') #Set of unnecessary punctuations\n",
    "    for i in range(len(df[col])):\n",
    "        without_punctuations = \"\"\n",
    "        for char in df[col][i]:\n",
    "            if(char not in punctuations):\n",
    "                without_punctuations = without_punctuations + char\n",
    "        df[col][i] = word_tokenize(without_punctuations)\n",
    "        \n",
    "    stops = set(stopwords_list()) #List of unnecessary words\n",
    "    for i in range(len(df[col])):\n",
    "        wordsWithoutStops = []\n",
    "        for j in range(len(df[col][i])):\n",
    "            if(df[col][i][j] not in stops):\n",
    "                wordsWithoutStops.append(lemmatizer.lemmatize(df[col][i][j]))\n",
    "        df[col][i] = wordsWithoutStops\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da647053",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "da647053",
    "outputId": "374d3a5b-5f24-49a7-8239-e538368643bd"
   },
   "outputs": [],
   "source": [
    "data_cleansed = dataCleanse(data, 'description')\n",
    "data_cleansed = dataCleanse(data_cleansed, 'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd0a695",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "9cd0a695",
    "outputId": "cfb4ebaf-0e35-4539-cc00-ce1f1b67c3b0"
   },
   "outputs": [],
   "source": [
    "data_cleansed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VsqddN55vSvA",
   "metadata": {
    "id": "VsqddN55vSvA"
   },
   "outputs": [],
   "source": [
    "def categorizer(data, brand, categories):\n",
    "    for i in range(len(data[brand])):\n",
    "        brand_i = data[brand][i]\n",
    "        if(brand_i in categories):\n",
    "            data[brand][i] = categories.get(brand_i)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iExeIURQu2Yg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "iExeIURQu2Yg",
    "outputId": "8ba8b7da-2d8a-40b7-922f-7b4dbf33fae9"
   },
   "outputs": [],
   "source": [
    "unique_Categories_cars = data_cleansed['category'].unique()\n",
    "categories_cars ={}\n",
    "for i in range(len(unique_Categories_cars)):\n",
    "    categories_cars[unique_Categories_cars[i]] = i\n",
    "for category in categories_cars:\n",
    "    print(\"Mapped: \",category,\" -> \", categories_cars.get(category))\n",
    "data_cleansed = categorizer(data_cleansed, 'category', categories_cars)\n",
    "data_cleansed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tfkh8o2px61t",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 765
    },
    "id": "tfkh8o2px61t",
    "outputId": "f451b7d8-533d-4c0b-8b96-5b1bd890b2d9"
   },
   "outputs": [],
   "source": [
    "MMScaler = MinMaxScaler()\n",
    "data_cleansed[['mileage']] = MMScaler.fit_transform(data_cleansed[['mileage']])\n",
    "data_cleansed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XrmnKUZEckMZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 586
    },
    "id": "XrmnKUZEckMZ",
    "outputId": "b08d083d-2d64-4efe-efae-9ff9bbce8be0"
   },
   "outputs": [],
   "source": [
    "data_cleansed_withOut_price = data_cleansed.drop(columns = ['price'])\n",
    "data_cleansed_withOut_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kDb2cwRBd7Zi",
   "metadata": {
    "id": "kDb2cwRBd7Zi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CA4_810098002.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
